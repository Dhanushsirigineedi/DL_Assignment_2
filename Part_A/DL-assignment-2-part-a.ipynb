{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11447255,"sourceType":"datasetVersion","datasetId":7171724},{"sourceId":11447814,"sourceType":"datasetVersion","datasetId":7172145}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Standard library imports\nimport math\nimport argparse\nfrom torch.utils.data import DataLoader, Subset\n\n# Third-party library imports\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch import optim\nfrom tqdm import tqdm\n\n# Torchvision imports\nimport torchvision\nfrom torchvision import datasets\nfrom torchvision.datasets import ImageFolder\nimport torchvision.transforms as transforms","metadata":{"id":"3jThqkXDJIQ0","execution":{"iopub.status.busy":"2025-04-19T12:33:18.271841Z","iopub.execute_input":"2025-04-19T12:33:18.272117Z","iopub.status.idle":"2025-04-19T12:33:18.276812Z","shell.execute_reply.started":"2025-04-19T12:33:18.272097Z","shell.execute_reply":"2025-04-19T12:33:18.275933Z"},"trusted":true},"outputs":[],"execution_count":12},{"cell_type":"code","source":"!pip install --upgrade wandb\nimport wandb\n# import socket\n# socket.setdefaulttimeout(30)\nwandb.login(key='1d2423ec9b728fe6cc1e2c0b9a2af0e67a45183c')\n","metadata":{"id":"NCprfCfLdHvK","trusted":true,"outputId":"b3f9eb38-cb52-4125-912b-db2a7806f753","execution":{"iopub.status.busy":"2025-04-19T12:31:48.646252Z","iopub.execute_input":"2025-04-19T12:31:48.646543Z","iopub.status.idle":"2025-04-19T12:32:14.920995Z","shell.execute_reply.started":"2025-04-19T12:31:48.646526Z","shell.execute_reply":"2025-04-19T12:32:14.920163Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.6)\nCollecting wandb\n  Downloading wandb-0.19.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\nRequirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.7)\nRequirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.20.3)\nRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (7.0.0)\nRequirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.3)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\nRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\nRequirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.21.0)\nRequirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.4)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.1.0)\nRequirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.13.1)\nRequirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\nDownloading wandb-0.19.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.9/20.9 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: wandb\n  Attempting uninstall: wandb\n    Found existing installation: wandb 0.19.6\n    Uninstalling wandb-0.19.6:\n      Successfully uninstalled wandb-0.19.6\nSuccessfully installed wandb-0.19.9\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs24m047\u001b[0m (\u001b[33mcs24m047-iitm-ac-in\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"# from google.colab import drive\n# drive.mount('/content/drive')","metadata":{"id":"zior74QKD2ob","outputId":"c41b6904-ccab-44c3-c92c-7e60f2593ab8","trusted":true,"execution":{"iopub.status.busy":"2025-04-19T12:32:14.922738Z","iopub.execute_input":"2025-04-19T12:32:14.923140Z","iopub.status.idle":"2025-04-19T12:32:14.926522Z","shell.execute_reply.started":"2025-04-19T12:32:14.923121Z","shell.execute_reply":"2025-04-19T12:32:14.925743Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# path in kaggle for the datasets\ntrain_directory='/kaggle/input/dataset2/inaturalist_12K/train'\ntest_directory='/kaggle/input/dataset2/inaturalist_12K/val'","metadata":{"id":"1xVh41hAIgwf","trusted":true,"execution":{"iopub.status.busy":"2025-04-19T12:32:14.927278Z","iopub.execute_input":"2025-04-19T12:32:14.927525Z","iopub.status.idle":"2025-04-19T12:32:14.943371Z","shell.execute_reply.started":"2025-04-19T12:32:14.927508Z","shell.execute_reply":"2025-04-19T12:32:14.942653Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"class CNN(nn.Module):\n    def __init__(self, no_of_input_channels=3, no_of_classes=10, no_of_filters=[32,32,32,32,32], size_of_filter=[3,3,3,3,3],\n                 no_of_neurons=128, activation_function='sigmoid',dropout_probability=0.0, batch_normalization='no'):\n        super(CNN, self).__init__()\n        self.activation_function_name = activation_function\n        self.batch_normalization = batch_normalization\n        \n        width = height = 256.0 # Initialize width and height for feature map calculations\n        \n        # Create convolutional, batch norm, and pooling layers dynamically\n        for i in range(len(no_of_filters)):\n            # Conv layer\n            conv_layer = nn.Conv2d(in_channels=no_of_input_channels if i == 0 else no_of_filters[i-1],\n                                   out_channels=no_of_filters[i],kernel_size=size_of_filter[i],stride=1)\n            setattr(self, f'conv_layer{i+1}', conv_layer)\n\n            width = height = (width - size_of_filter[i]) + 1  # Update feature map dimensions after convolution\n            # Batch norm layer\n            if batch_normalization == 'yes':\n                batch_norm = nn.BatchNorm2d(no_of_filters[i])\n                setattr(self, f'batch_norm{i+1}', batch_norm) \n            # Pooling layer\n            pool_layer = nn.MaxPool2d(kernel_size=size_of_filter[i], stride=2)\n            setattr(self, f'pool_layer{i+1}', pool_layer)\n            width = height = math.floor((width - size_of_filter[i]) / 2) + 1 # Update feature map dimensions after pooling\n        # Fully connected layers\n        self.dropout = nn.Dropout(p=dropout_probability)\n        self.full_connected1 = nn.Linear(no_of_filters[-1] * int(width) * int(height), no_of_neurons) \n        if batch_normalization == 'yes':\n            self.batch_norm6 = nn.BatchNorm1d(no_of_neurons) \n        self.full_connected2 = nn.Linear(no_of_neurons, no_of_classes)\n\n    def forward(self, x):\n      # Set activation function\n      if(self.activation_function_name == 'relu'):\n            activation_function = F.relu\n      elif(self.activation_function_name == 'gelu'):\n          activation_function = F.gelu\n      elif(self.activation_function_name == 'silu'):\n          activation_function = F.silu\n      else:\n            activation_function = F.mish\n\n      # Process through 5 convolutional blocks\n      for i in range(1, 6):\n          conv_layer = getattr(self, f'conv_layer{i}')\n          if self.batch_normalization == 'yes':\n              batch_norm = getattr(self, f'batch_norm{i}')\n              x = activation_function(batch_norm(conv_layer(x)))\n          else:\n              x = activation_function(conv_layer(x)) \n          pool_layer = getattr(self, f'pool_layer{i}')\n          x = pool_layer(x)\n      # Flatten the output\n      x = x.reshape(x.shape[0], -1)\n      # First fully connected layer\n      if self.batch_normalization == 'yes':\n          x = activation_function(self.batch_norm6(self.full_connected1(x)))\n      else:\n          x = activation_function(self.full_connected1(x))\n      x = self.dropout(x)\n      x = self.full_connected2(x)\n      return x","metadata":{"id":"FsGQWkx6JNw4","execution":{"iopub.status.busy":"2025-04-19T12:32:14.944261Z","iopub.execute_input":"2025-04-19T12:32:14.944520Z","iopub.status.idle":"2025-04-19T12:32:14.960867Z","shell.execute_reply.started":"2025-04-19T12:32:14.944499Z","shell.execute_reply":"2025-04-19T12:32:14.960082Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"id":"82Wbat2GLjXW","outputId":"32654a5e-f24b-4f19-e455-18fb5c277aba","trusted":true,"execution":{"iopub.status.busy":"2025-04-19T12:32:14.961693Z","iopub.execute_input":"2025-04-19T12:32:14.961898Z","iopub.status.idle":"2025-04-19T12:32:15.042263Z","shell.execute_reply.started":"2025-04-19T12:32:14.961881Z","shell.execute_reply":"2025-04-19T12:32:15.041411Z"}},"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"transform_basic = transforms.Compose([\n    transforms.Resize((256,256)), # resized to a threshold value so that all images have same shape and size\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,),(0.5,))]) # normalized for better accuracy.\n\ntrain_dataset = datasets.ImageFolder(root=train_directory,transform=transform_basic) # train_data loading\ntraining_dataset,validation_dataset = torch.utils.data.random_split(train_dataset,[8000,1999]) #splitting the data into 80%(training) and 20%(validation) The overall data size is 9999\n\ntransform_augmented = transforms.Compose([\n    transforms.RandomHorizontalFlip(),  # Randomly flip the image horizontally\n    transforms.RandomRotation(10),      # Randomly rotate the image by a maximum of 10 degrees\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Adjust brightness, contrast, saturation, and hue\n    transforms.RandomResizedCrop(256),  # Randomly crop and resize the image to 256x256\n    transforms.ToTensor(),              # Convert the image to a PyTorch tensor\n    transforms.Normalize((0.5,),(0.5,))  # Normalize the image\n]) # for augumenting the training data\ntrain_dataset2 = datasets.ImageFolder(root=train_directory,transform=transform_augmented)\ntraining_dataset_aug,validation_dataset_aug = torch.utils.data.random_split(train_dataset2,[8000,1999]) #  #splitting the data into 80%(training) and 20%(validation) The overall data size is 9999\n\ntest_dataset = datasets.ImageFolder(root=test_directory,transform=transform_basic); # test data loading.","metadata":{"id":"s8RAqFPBLkF-","trusted":true,"execution":{"iopub.status.busy":"2025-04-19T12:32:15.043127Z","iopub.execute_input":"2025-04-19T12:32:15.043445Z","iopub.status.idle":"2025-04-19T12:32:27.800070Z","shell.execute_reply.started":"2025-04-19T12:32:15.043417Z","shell.execute_reply":"2025-04-19T12:32:27.799336Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def data_loader_creator(augmentation_flag,batch_size): # function to return the data loaders depending on augumentation.\n    if(augmentation_flag == 'no'):\n        train_loader = torch.utils.data.DataLoader(training_dataset,batch_size =batch_size,shuffle = True,num_workers=2,pin_memory=True)\n        val_loader = torch.utils.data.DataLoader(validation_dataset,batch_size =batch_size,shuffle = True,num_workers=2,pin_memory=True)\n        return train_loader,val_loader\n    else:\n        train_loader_aug = torch.utils.data.DataLoader(training_dataset_aug,batch_size =batch_size,shuffle = True,num_workers=4,pin_memory=True)\n        val_loader_aug = torch.utils.data.DataLoader(validation_dataset_aug,batch_size =batch_size,shuffle = True,num_workers=4,pin_memory=True)\n        return train_loader_aug,val_loader_aug","metadata":{"id":"xwvPIxbbQwJo","trusted":true,"execution":{"iopub.status.busy":"2025-04-19T12:32:27.800852Z","iopub.execute_input":"2025-04-19T12:32:27.801108Z","iopub.status.idle":"2025-04-19T12:32:27.806137Z","shell.execute_reply.started":"2025-04-19T12:32:27.801081Z","shell.execute_reply":"2025-04-19T12:32:27.805445Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def Accuracy_calculator(loader, model, criterion, batch_size):\n    \"\"\"Computes model accuracy and average loss on a given dataset loader\"\"\"\n    correct_predictions = 0\n    total_samples = 0\n    accumulated_loss = 0.0\n    model.eval()  # Set model to evaluation mode\n    \n    with torch.no_grad():  # Disable gradient computation\n        for inputs, targets in loader:\n            # Move data to the appropriate device\n            inputs = inputs.to(device)\n            targets = targets.to(device)\n            # Forward pass\n            outputs = model(inputs)\n            loss = criterion(outputs, targets)\n            # Update metrics\n            accumulated_loss += loss.item() * batch_size\n            _, predicted = outputs.max(1)\n            correct_predictions += (predicted == targets).sum().item()\n            total_samples += predicted.size(0)\n    model.train()  # Restore model to training mode\n    accuracy = (correct_predictions / total_samples) * 100\n    average_loss = accumulated_loss / total_samples\n    return accuracy, average_loss","metadata":{"id":"Yq0mYvsqWZp0","trusted":true,"execution":{"iopub.status.busy":"2025-04-19T12:32:27.807675Z","iopub.execute_input":"2025-04-19T12:32:27.808158Z","iopub.status.idle":"2025-04-19T12:32:27.828144Z","shell.execute_reply.started":"2025-04-19T12:32:27.808132Z","shell.execute_reply":"2025-04-19T12:32:27.827632Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def train_the_model(no_of_neurons, no_of_filters, size_of_filter, activation_function_name, optimizer_name, batch_size,\n                   dropout_probability, no_of_epochs, learning_rate, batch_normalization, augmentation_flag):\n    no_of_input_channels = 3\n    no_of_classes = 10\n\n    train_loader, val_loader = data_loader_creator(augmentation_flag, batch_size)  # getting dataloaders\n    # Uncomment the below line for test data loader\n    # test_loader = torch.utils.data.DataLoader(test_data,batch_size=batch_size,shuffle=True,num_workers=2,pin_memory=True)\n    \n    model = CNN(no_of_input_channels, no_of_classes, no_of_filters, size_of_filter, no_of_neurons,\n                activation_function_name, dropout_probability, batch_normalization).to(device)\n    # model=nn.DataParallel(model)\n    # model=model.to(device)\n\n    if optimizer_name == 'sgd':\n        optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n    elif optimizer_name == 'adam':\n        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n    else:\n        optimizer = optim.NAdam(model.parameters(), lr=learning_rate)  # optimzers selection\n    criterion = nn.CrossEntropyLoss()  # since it is classification problem corss entropy loss is used.\n\n    for epoch in range(no_of_epochs):\n        for batchId, (input_images, target_classes) in enumerate(tqdm(train_loader)):\n            input_images = input_images.to(device=device)\n            target_classes = target_classes.to(device=device)\n            # forward\n            scores = model(input_images)  # give the last layer pre-activation values.\n            loss = criterion(scores, target_classes)  # gets the overll cross entropy loss for each batch\n            \n            optimizer.zero_grad()  # gradients are made to zero for each batch.\n            loss.backward()  # calculaing the gradients\n            optimizer.step()  # updates the parameters\n        \n        training_accuracy, training_loss = Accuracy_calculator(train_loader, model, criterion, batch_size)\n        validation_accuracy, validation_loss = Accuracy_calculator(val_loader, model, criterion, batch_size)\n        \n        # Uncomment the below lines for test data evaluation\n        # test_accuracy, test_loss = Accuracy_calculator(test_loader, model, criterion, batch_size)\n        # print(f\"test_accuracy:{test_accuracy:.4f},test_loss:{test_loss:.4f}\")\n        # wandb.log({'test_accuracy': test_accuracy})\n        # wandb.log({'test_loss': test_loss})\n        \n        print(f\"training_accuracy:{training_accuracy:.4f},training_loss:{training_loss:.4f}\")\n        print(f\"validation_accuracy:{validation_accuracy:.4f},validation_loss:{validation_loss:.4f}\")\n        wandb.log({'training_accuracy': training_accuracy})  # plotting the data in wandb\n        wandb.log({'training_loss': training_loss})\n        wandb.log({'validation_accuracy': validation_accuracy})\n        wandb.log({'validation_loss': validation_loss})","metadata":{"id":"tjVu69UXSi6X","trusted":true,"execution":{"iopub.status.busy":"2025-04-19T12:32:27.828750Z","iopub.execute_input":"2025-04-19T12:32:27.828945Z","iopub.status.idle":"2025-04-19T12:32:27.843181Z","shell.execute_reply.started":"2025-04-19T12:32:27.828930Z","shell.execute_reply":"2025-04-19T12:32:27.842524Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def parse_arguments():\n    parser = argparse.ArgumentParser(description='Training_Parameters')\n\n    parser.add_argument('-wp', '--wandb_project', type=str, default='DA6401_Assignment_2',\n                      help='Project name used to track experiments in Weights & Biases dashboard')\n    \n    parser.add_argument('-n', '--no_of_neurons', type=int, default=128, \n                      choices=[128, 256, 512], help='Number of neurons in dense layer')\n    \n    parser.add_argument('-nF', '--no_of_filters', type=str, default='32,64,128,256,512',\n                      help='Number of filters per layer as comma-separated values')\n    \n    parser.add_argument('-sF', '--size_of_filter', type=str, default='3,3,3,3,3',\n                      help='Filter sizes per layer as comma-separated values')\n\n    parser.add_argument('-aF', '--activation_function_name', type=str, default='gelu', \n                      choices=['relu','gelu','silu','mish'], help='Activation function type')\n    \n    parser.add_argument('-opt', '--optimizer_name', type=str, default='nadam', \n                      choices=['adam','nadam'], help='Optimizer type')\n\n    parser.add_argument('-bS', '--batch_size', type=int, default=32, \n                      choices=[32, 64, 128], help='Batch size for training')\n\n    parser.add_argument('-d', '--dropout_probability', type=float, default=0.4, \n                      choices=[0, 0.2, 0.4], help='Dropout probability')\n\n    parser.add_argument('-nE', '--no_of_epochs', type=int, default=10, \n                      choices=[5, 10], help='Number of training epochs')\n\n    parser.add_argument('-lR', '--learning_rate', type=float, default=0.001, \n                      choices=[1e-3, 1e-4], help='Learning rate')\n\n    parser.add_argument('-bN', '--batch_normalization', type=str, default='yes', \n                      choices=['yes','no'], help='Whether to use batch normalization')\n\n    parser.add_argument('-ag', '--augmentation_flag', type=str, default='no', \n                      choices=['yes','no'], help='Whether to use data augmentation')\n\n    return parser.parse_args()\n\nargs = parse_arguments()\nargs.no_of_filters = [int(x) for x in args.no_of_filters.split(',')]\nargs.size_of_filter = [int(x) for x in args.size_of_filter.split(',')]\nwandb.init(project=args.wandb_project)\n\nwandb.run.name = (\n    f\"No_of_neurons: {args.no_of_neurons}, \"\n    f\"No_of_filters: {args.no_of_filters}, \"\n    f\"Size_of_filter: {args.size_of_filter}, \"\n    f\"Activation_function: {args.activation_function_name}, \"\n    f\"Optimizer: {args.optimizer_name}, \"\n    f\"Batch_size: {args.batch_size}, \"\n    f\"Dropout: {args.dropout_probability}, \"\n    f\"No_of_epochs: {args.no_of_epochs}, \"\n    f\"Learning_Rate: {args.learning_rate}, \"\n    f\"Batch_normalization: {args.batch_normalization}, \"\n    f\"Augmentation_flag: {args.augmentation_flag}\"\n)\n\ntrain_the_model(\n    args.no_of_neurons,\n    args.no_of_filters,\n    args.size_of_filter,\n    args.activation_function_name,\n    args.optimizer_name,\n    args.batch_size,\n    args.dropout_probability,\n    args.no_of_epochs,\n    args.learning_rate,\n    args.batch_normalization,\n    args.augmentation_flag\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T12:33:27.555975Z","iopub.execute_input":"2025-04-19T12:33:27.556301Z","iopub.status.idle":"2025-04-19T12:33:27.569291Z","shell.execute_reply.started":"2025-04-19T12:33:27.556280Z","shell.execute_reply":"2025-04-19T12:33:27.568245Z"}},"outputs":[{"name":"stderr","text":"usage: colab_kernel_launcher.py [-h] [-wp WANDB_PROJECT] [-n {128,256,512}] [-nF NO_OF_FILTERS]\n                                [-sF SIZE_OF_FILTER] [-aF {relu,gelu,silu,mish}]\n                                [-opt {adam,nadam}] [-bS {32,64,128}] [-d {0,0.2,0.4}]\n                                [-nE {5,10}] [-lR {0.001,0.0001}] [-bN {yes,no}] [-ag {yes,no}]\ncolab_kernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-c62b995f-2e89-4c08-9440-5175305cd488.json\n","output_type":"stream"},{"traceback":["An exception has occurred, use %tb to see the full traceback.\n","\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"],"ename":"SystemExit","evalue":"2","output_type":"error"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py:3561: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# Sweep config for wandb plotting\n# wandb.init(project ='DA6401_Assignment_2')\nsweep_config = {\n    'name'  : \"final_code_5\",\n    'method': 'bayes',\n    'metric': {\n      'name': 'validation_accuracy',\n      'goal': 'maximize'\n    },\n    'parameters': {\n        'no_of_neurons': {\n            'values': [128, 256, 512]\n        },\n        'no_of_filters': {\n            'values': [[64,128,256,512, 1024], [32,32,32,32,32],[32,64,64,128,128],[128,128,64,64,32],[32,64,128,256,512]]\n        },\n        'size_of_filter': {\n            'values': [[3,3,3,3,3], [5,5,5,5,5], [5,3,5,3,5]]\n        },\n        'activation_function_name': {\n            'values': ['relu','gelu','silu','mish']\n        },\n        'optimizer_name': {\n            'values': ['nadam', 'adam']\n        },\n        'batch_size': {\n            'values': [32, 64,128]\n        },\n        'dropout_probability': {\n            'values': [0, 0.2, 0.4]\n        },\n        'no_of_epochs': {\n            'values': [5,10]\n        },\n        'learning_rate': {\n            'values': [1e-3, 1e-4]\n        },\n        'batch_normalization': {\n            'values': ['yes','no']\n        },\n        'augmentation_flag': {\n            'values': ['yes','no']\n        }\n    }\n}","metadata":{"id":"aFev94lk6P5v","outputId":"9186cd5b-9628-4708-a8d5-e979d37d1598","trusted":true,"execution":{"iopub.status.busy":"2025-04-19T10:17:56.120929Z","iopub.execute_input":"2025-04-19T10:17:56.121152Z","iopub.status.idle":"2025-04-19T10:17:56.140586Z","shell.execute_reply.started":"2025-04-19T10:17:56.121128Z","shell.execute_reply":"2025-04-19T10:17:56.139918Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def run_experiment():\n    try:\n        run = wandb.init()  # No config argument here\n        cfg = run.config\n        run.name = (\n            f\"No_of_neurons: {cfg.no_of_neurons}, \"\n            f\"No_of_filters: {cfg.no_of_filters}, \"\n            f\"Size_of_filter: {cfg.size_of_filter}, \"\n            f\"Activation_function: {cfg.activation_function_name}, \"\n            f\"Optimizer: {cfg.optimizer_name}, \"\n            f\"Batch_size: {cfg.batch_size}, \"\n            f\"Dropout: {cfg.dropout_probability}, \"\n            f\"No_of_epochs: {cfg.no_of_epochs}, \"\n            f\"Learning_Rate: {cfg.learning_rate}, \"\n            f\"Batch_normalization: {cfg.batch_normalization}, \"\n            f\"Augmentation_flag: {cfg.augmentation_flag}\"\n        )\n        train_the_model(\n            cfg.no_of_neurons,\n            cfg.no_of_filters,\n            cfg.size_of_filter,\n            cfg.activation_function_name,\n            cfg.optimizer_name,\n            cfg.batch_size,\n            cfg.dropout_probability,\n            cfg.no_of_epochs,\n            cfg.learning_rate,\n            cfg.batch_normalization,\n            cfg.augmentation_flag\n        )\n    except Exception as e:\n        print(f\"Error during training: {e}\")\n        if wandb.run:\n            wandb.finish(exit_code=1)\n        raise\n    finally:\n        if wandb.run:\n            wandb.finish\nif __name__==\"__main__\":\n    sweep_id = wandb.sweep(sweep_config, project=\"DA6401_Assignment_2\")\n    wandb.agent(sweep_id, run_experiment ,  count=5)","metadata":{"id":"eWap7rHM6S3v","outputId":"2465c9f6-7d5d-437d-ba0b-655d9c8e13a0","trusted":true,"execution":{"iopub.status.busy":"2025-04-19T10:17:56.141174Z","iopub.execute_input":"2025-04-19T10:17:56.141556Z","execution_failed":"2025-04-19T10:30:27.770Z"}},"outputs":[{"name":"stdout","text":"Create sweep with ID: 8lnmtrxl\nSweep URL: https://wandb.ai/cs24m047-iitm-ac-in/DA6401_Assignment_2/sweeps/8lnmtrxl\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: fonaha9k with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_function_name: gelu\n\u001b[34m\u001b[1mwandb\u001b[0m: \taugmentation_flag: no\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_normalization: no\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_probability: 0.4\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tno_of_epochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tno_of_filters: [32, 32, 32, 32, 32]\n\u001b[34m\u001b[1mwandb\u001b[0m: \tno_of_neurons: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_name: adam\n\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_of_filter: [5, 5, 5, 5, 5]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250419_101804-fonaha9k</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs24m047-iitm-ac-in/DA6401_Assignment_2/runs/fonaha9k' target=\"_blank\">zesty-sweep-1</a></strong> to <a href='https://wandb.ai/cs24m047-iitm-ac-in/DA6401_Assignment_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m047-iitm-ac-in/DA6401_Assignment_2/sweeps/8lnmtrxl' target=\"_blank\">https://wandb.ai/cs24m047-iitm-ac-in/DA6401_Assignment_2/sweeps/8lnmtrxl</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs24m047-iitm-ac-in/DA6401_Assignment_2' target=\"_blank\">https://wandb.ai/cs24m047-iitm-ac-in/DA6401_Assignment_2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs24m047-iitm-ac-in/DA6401_Assignment_2/sweeps/8lnmtrxl' target=\"_blank\">https://wandb.ai/cs24m047-iitm-ac-in/DA6401_Assignment_2/sweeps/8lnmtrxl</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs24m047-iitm-ac-in/DA6401_Assignment_2/runs/fonaha9k' target=\"_blank\">https://wandb.ai/cs24m047-iitm-ac-in/DA6401_Assignment_2/runs/fonaha9k</a>"},"metadata":{}},{"name":"stderr","text":"100%|██████████| 250/250 [00:49<00:00,  5.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"training_accuracy:20.0625,training_loss:2.1623\nvalidation_accuracy:18.7094,validation_loss:2.1833\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 250/250 [00:52<00:00,  4.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"training_accuracy:23.8375,training_loss:2.1113\nvalidation_accuracy:23.9620,validation_loss:2.1240\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 250/250 [00:51<00:00,  4.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"training_accuracy:28.1500,training_loss:2.0108\nvalidation_accuracy:27.2636,validation_loss:2.0513\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 250/250 [00:53<00:00,  4.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"training_accuracy:28.2125,training_loss:2.0204\nvalidation_accuracy:26.9135,validation_loss:2.0669\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 250/250 [00:52<00:00,  4.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"training_accuracy:30.8375,training_loss:1.9233\nvalidation_accuracy:30.6153,validation_loss:1.9639\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>training_accuracy</td><td>▁▃▆▆█</td></tr><tr><td>training_loss</td><td>█▇▄▄▁</td></tr><tr><td>validation_accuracy</td><td>▁▄▆▆█</td></tr><tr><td>validation_loss</td><td>█▆▄▄▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>training_accuracy</td><td>30.8375</td></tr><tr><td>training_loss</td><td>1.92327</td></tr><tr><td>validation_accuracy</td><td>30.61531</td></tr><tr><td>validation_loss</td><td>1.96393</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">No_of_neurons: 256, No_of_filters: [32, 32, 32, 32, 32], Size_of_filter: [5, 5, 5, 5, 5], Activation_function: gelu, Optimizer: adam, Batch_size: 32, Dropout: 0.4, No_of_epochs: 5, Learning_Rate: 0.001, Batch_normalization: no, Augmentation_flag: no</strong> at: <a href='https://wandb.ai/cs24m047-iitm-ac-in/DA6401_Assignment_2/runs/fonaha9k' target=\"_blank\">https://wandb.ai/cs24m047-iitm-ac-in/DA6401_Assignment_2/runs/fonaha9k</a><br> View project at: <a href='https://wandb.ai/cs24m047-iitm-ac-in/DA6401_Assignment_2' target=\"_blank\">https://wandb.ai/cs24m047-iitm-ac-in/DA6401_Assignment_2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250419_101804-fonaha9k/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mrjqiy7s with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_function_name: relu\n\u001b[34m\u001b[1mwandb\u001b[0m: \taugmentation_flag: yes\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_normalization: yes\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_probability: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tno_of_epochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \tno_of_filters: [128, 128, 64, 64, 32]\n\u001b[34m\u001b[1mwandb\u001b[0m: \tno_of_neurons: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_name: adam\n\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_of_filter: [3, 3, 3, 3, 3]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250419_102756-mrjqiy7s</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs24m047-iitm-ac-in/DA6401_Assignment_2/runs/mrjqiy7s' target=\"_blank\">decent-sweep-2</a></strong> to <a href='https://wandb.ai/cs24m047-iitm-ac-in/DA6401_Assignment_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m047-iitm-ac-in/DA6401_Assignment_2/sweeps/8lnmtrxl' target=\"_blank\">https://wandb.ai/cs24m047-iitm-ac-in/DA6401_Assignment_2/sweeps/8lnmtrxl</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs24m047-iitm-ac-in/DA6401_Assignment_2' target=\"_blank\">https://wandb.ai/cs24m047-iitm-ac-in/DA6401_Assignment_2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs24m047-iitm-ac-in/DA6401_Assignment_2/sweeps/8lnmtrxl' target=\"_blank\">https://wandb.ai/cs24m047-iitm-ac-in/DA6401_Assignment_2/sweeps/8lnmtrxl</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs24m047-iitm-ac-in/DA6401_Assignment_2/runs/mrjqiy7s' target=\"_blank\">https://wandb.ai/cs24m047-iitm-ac-in/DA6401_Assignment_2/runs/mrjqiy7s</a>"},"metadata":{}},{"name":"stderr","text":" 78%|███████▊  | 97/125 [02:24<00:41,  1.48s/it]","output_type":"stream"}],"execution_count":null}]}