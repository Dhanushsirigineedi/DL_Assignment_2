{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11447255,"sourceType":"datasetVersion","datasetId":7171724},{"sourceId":11447814,"sourceType":"datasetVersion","datasetId":7172145}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torchvision.datasets import ImageFolder\nimport torchvision.transforms as transforms\nfrom torch.utils.data import Subset, DataLoader\nimport torchvision\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch import optim\nfrom tqdm import tqdm\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets\nimport torchvision.models as models","metadata":{"id":"3jThqkXDJIQ0","trusted":true,"execution":{"iopub.status.busy":"2025-04-18T13:04:33.182178Z","iopub.execute_input":"2025-04-18T13:04:33.182377Z","iopub.status.idle":"2025-04-18T13:04:41.101627Z","shell.execute_reply.started":"2025-04-18T13:04:33.182358Z","shell.execute_reply":"2025-04-18T13:04:41.101039Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"!pip install --upgrade wandb\nimport wandb\n# import socket\n# socket.setdefaulttimeout(30)\nwandb.login(key='1d2423ec9b728fe6cc1e2c0b9a2af0e67a45183c')\n","metadata":{"id":"NCprfCfLdHvK","trusted":true,"colab":{"base_uri":"https://localhost:8080/","height":596},"outputId":"b3f9eb38-cb52-4125-912b-db2a7806f753","execution":{"iopub.status.busy":"2025-04-18T13:04:44.462269Z","iopub.execute_input":"2025-04-18T13:04:44.462640Z","iopub.status.idle":"2025-04-18T13:05:10.899725Z","shell.execute_reply.started":"2025-04-18T13:04:44.462616Z","shell.execute_reply":"2025-04-18T13:05:10.899143Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.6)\nCollecting wandb\n  Downloading wandb-0.19.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\nRequirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.7)\nRequirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.20.3)\nRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (7.0.0)\nRequirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.3)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\nRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\nRequirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.21.0)\nRequirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.4)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.1.0)\nRequirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.13.1)\nRequirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\nDownloading wandb-0.19.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.9/20.9 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: wandb\n  Attempting uninstall: wandb\n    Found existing installation: wandb 0.19.6\n    Uninstalling wandb-0.19.6:\n      Successfully uninstalled wandb-0.19.6\nSuccessfully installed wandb-0.19.9\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs24m047\u001b[0m (\u001b[33mcs24m047-iitm-ac-in\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"# from google.colab import drive\n# drive.mount('/content/drive')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zior74QKD2ob","outputId":"c41b6904-ccab-44c3-c92c-7e60f2593ab8","trusted":true,"execution":{"iopub.status.busy":"2025-04-18T13:05:24.164138Z","iopub.execute_input":"2025-04-18T13:05:24.164566Z","iopub.status.idle":"2025-04-18T13:05:24.168116Z","shell.execute_reply.started":"2025-04-18T13:05:24.164544Z","shell.execute_reply":"2025-04-18T13:05:24.167397Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"train_directory='/kaggle/input/dataset2/inaturalist_12K/train'\ntest_directory='/kaggle/input/dataset2/inaturalist_12K/val'","metadata":{"id":"1xVh41hAIgwf","trusted":true,"execution":{"iopub.status.busy":"2025-04-18T13:05:26.588586Z","iopub.execute_input":"2025-04-18T13:05:26.589270Z","iopub.status.idle":"2025-04-18T13:05:26.592359Z","shell.execute_reply.started":"2025-04-18T13:05:26.589245Z","shell.execute_reply":"2025-04-18T13:05:26.591745Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"","metadata":{"id":"FsGQWkx6JNw4","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"82Wbat2GLjXW","outputId":"32654a5e-f24b-4f19-e455-18fb5c277aba","trusted":true,"execution":{"iopub.status.busy":"2025-04-18T13:05:29.516817Z","iopub.execute_input":"2025-04-18T13:05:29.517587Z","iopub.status.idle":"2025-04-18T13:05:29.587182Z","shell.execute_reply.started":"2025-04-18T13:05:29.517553Z","shell.execute_reply":"2025-04-18T13:05:29.586311Z"}},"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"transform_basic = transforms.Compose([\n    transforms.Resize((224,224)), #reshaped the data to be used by RESNET50\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,),(0.5,))]) # normalized for better accuracy.\n\ntrain_dataset = datasets.ImageFolder(root=train_directory,transform=transform_basic) # train_data loading\ntraining_dataset,validation_dataset = torch.utils.data.random_split(train_dataset,[8000,1999]) #splitting the data into 80%(training) and 20%(validation) The overall data size is 9999\n\ntransform_augmented = transforms.Compose([\n    transforms.RandomHorizontalFlip(),  # Randomly flip the image horizontally\n    transforms.RandomRotation(10),      # Randomly rotate the image by a maximum of 10 degrees\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Adjust brightness, contrast, saturation, and hue\n    transforms.RandomResizedCrop(224),  # Randomly crop and resize the image to 224x224\n    transforms.ToTensor(),              # Convert the image to a PyTorch tensor\n    transforms.Normalize((0.5,),(0.5,))  # Normalize the image\n]) # for augumenting the training data\ntrain_dataset2 = datasets.ImageFolder(root=train_directory,transform=transform_augmented)\ntraining_dataset_aug,validation_dataset_aug = torch.utils.data.random_split(train_dataset2,[8000,1999]) #  #splitting the data into 80%(training) and 20%(validation) The overall data size is 9999\n\ntest_dataset = datasets.ImageFolder(root=test_directory,transform=transform_basic); # test data loading.","metadata":{"id":"s8RAqFPBLkF-","trusted":true,"execution":{"iopub.status.busy":"2025-04-18T13:05:32.161038Z","iopub.execute_input":"2025-04-18T13:05:32.161764Z","iopub.status.idle":"2025-04-18T13:05:41.572510Z","shell.execute_reply.started":"2025-04-18T13:05:32.161736Z","shell.execute_reply":"2025-04-18T13:05:41.571934Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def data_loader_creator(augmentation_flag,batch_size): # function to return the data loaders depending on augumentation.\n    if(augmentation_flag == 'no'):\n        train_loader = torch.utils.data.DataLoader(training_dataset,batch_size =batch_size,shuffle = True,num_workers=2,pin_memory=True)\n        val_loader = torch.utils.data.DataLoader(validation_dataset,batch_size =batch_size,shuffle = True,num_workers=2,pin_memory=True)\n        return train_loader,val_loader\n    else:\n        train_loader_aug = torch.utils.data.DataLoader(training_dataset_aug,batch_size =batch_size,shuffle = True,num_workers=4,pin_memory=True)\n        val_loader_aug = torch.utils.data.DataLoader(validation_dataset_aug,batch_size =batch_size,shuffle = True,num_workers=4,pin_memory=True)\n        return train_loader_aug,val_loader_aug","metadata":{"id":"xwvPIxbbQwJo","trusted":true,"execution":{"iopub.status.busy":"2025-04-18T13:05:45.056581Z","iopub.execute_input":"2025-04-18T13:05:45.056855Z","iopub.status.idle":"2025-04-18T13:05:45.062116Z","shell.execute_reply.started":"2025-04-18T13:05:45.056835Z","shell.execute_reply":"2025-04-18T13:05:45.061397Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def RESNET50(NUM_OF_CLASSES): # this function returns the model by freezing all but not last layer\n    model = models.resnet50(pretrained=True)\n    num_ftrs = model.fc.in_features\n    model.fc = torch.nn.Linear(num_ftrs, NUM_OF_CLASSES) # modifying output layer to 10 neurons \n    \n    for param in model.parameters(): # freezing\n        param.requires_grad = False\n        \n    for param in model.fc.parameters(): #unfreezing\n        param.requires_grad = True\n   \n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T13:05:58.028822Z","iopub.execute_input":"2025-04-18T13:05:58.029088Z","iopub.status.idle":"2025-04-18T13:05:58.033500Z","shell.execute_reply.started":"2025-04-18T13:05:58.029061Z","shell.execute_reply":"2025-04-18T13:05:58.032798Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def RESNET50_1(k,NUM_OF_CLASSES): #this function returns the model by freezing first k layers only\n    model = models.resnet50(pretrained=True)    \n    \n    params = list(model.parameters())\n    for param in params[:k]:\n        param.requires_grad = False #freezing\n        \n    num_ftrs = model.fc.in_features\n    \n    model.fc = torch.nn.Linear(num_ftrs, NUM_OF_CLASSES)\n    \n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T13:06:01.629517Z","iopub.execute_input":"2025-04-18T13:06:01.630157Z","iopub.status.idle":"2025-04-18T13:06:01.634339Z","shell.execute_reply.started":"2025-04-18T13:06:01.630131Z","shell.execute_reply":"2025-04-18T13:06:01.633618Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def RESNET50_2(neurons_dense,NUM_OF_CLASSES): #this function returns the model by freezing all but not last layer after adding dense layer\n    \n    model = models.resnet50(pretrained=True)    \n    \n    activation_function_layer = nn.ReLU()\n    \n    for params in model.parameters():\n        params.requires_grad = False #freezing\n        \n    num_ftrs = model.fc.in_features\n    \n    model.fc = nn.Sequential(\n      nn.Linear(num_ftrs,neurons_dense), #adding dense layer\n      activation_function_layer,\n      nn.Dropout(0.4),\n      nn.Linear(neurons_dense, 10)\n    )\n\n    for param in model.fc.parameters():\n        param.requires_grad = True  #unfreezing\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T13:06:04.960562Z","iopub.execute_input":"2025-04-18T13:06:04.961246Z","iopub.status.idle":"2025-04-18T13:06:04.966309Z","shell.execute_reply.started":"2025-04-18T13:06:04.961221Z","shell.execute_reply":"2025-04-18T13:06:04.965351Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def Accuracy_calculator(loader,model,criterion,batch_size): # function to clculate the accuracy and loss\n    no_of_correct_predictions = 0\n    no_of_samples = 0\n    total_loss = 0.0\n    model.eval()\n    with torch.no_grad():\n        for x, y in loader:\n            x = x.to(device=device)\n            y = y.to(device=device)\n            scores = model(x)\n            loss = criterion(scores, y)\n            total_loss += loss.item()*batch_size # sum of cross entropies\n            _, predictions = scores.max(1)\n            no_of_correct_predictions += (predictions == y).sum().item() # correctly classified data\n            no_of_samples += predictions.size(0)\n    model.train()\n    return (no_of_correct_predictions / no_of_samples)*100 , total_loss / no_of_samples","metadata":{"id":"Yq0mYvsqWZp0","trusted":true,"execution":{"iopub.status.busy":"2025-04-18T13:06:08.925311Z","iopub.execute_input":"2025-04-18T13:06:08.925843Z","iopub.status.idle":"2025-04-18T13:06:08.930624Z","shell.execute_reply.started":"2025-04-18T13:06:08.925818Z","shell.execute_reply":"2025-04-18T13:06:08.929841Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def train_the_model(batch_size,no_of_epochs,learning_rate,augmentation_flag,strategy_flag,NUM_OF_CLASSES):\n\n    train_loader,val_loader = data_loader_creator(augmentation_flag,batch_size)  # getting dataloaders.\n\n    #test_loader = torch.utils.data.DataLoader(test_data,batch_size =batchSize,shuffle = True,num_workers=2,pin_memory=True)\n\n    no_of_input_channels=3\n    no_of_classes=10\n\n    if(strategy_flag == 0):\n        model = RESNET50(NUM_OF_CLASSES).to(device)\n    elif(strategy_flag == 1):\n        model = RESNET50_1(10,NUM_OF_CLASSES).to(device)\n    else:\n        model = RESNET50_2(256,NUM_OF_CLASSES).to(device)\n\n    # model=CNN(no_of_input_channels, no_of_classes,no_of_filters,size_of_filter,no_of_neurons,\n    #           activation_function_name,dropout_probability,batch_normalization)\n    # model=nn.DataParallel(model)\n    # model=model.to(device)\n\n    # if(optimizer_name == 'sgd'):\n    #     optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n    # elif(optimizer_name == 'adam'):\n    #     optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n    # else:\n    #   optimizer = optim.NAdam(model.parameters(), lr=learning_rate) # optimzers selection\n\n    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n    criterion = nn.CrossEntropyLoss() # since it is classification problem corss entropy loss is used.\n\n    for epoch in range(no_of_epochs): # performs the training.\n        for batchId, (input_images, target_classes) in enumerate(tqdm(train_loader)):\n            # Get data to cuda if possible\n            input_images = input_images.to(device=device)\n            target_classes = target_classes.to(device=device)\n            # forward\n            scores = model(input_images) # give the last layer pre-activation values.\n            loss = criterion(scores,target_classes) # gets the overll cross entropy loss for each batch\n            optimizer.zero_grad() # gradients are made to zero for each batch.\n            loss.backward()  # calculaing the gradients\n            optimizer.step() #updates the parameters\n        training_accuracy,training_loss = Accuracy_calculator(train_loader, model,criterion,batch_size) # calculates the accuracy and loss at one go\n        validation_accuracy,validation_loss = Accuracy_calculator(val_loader, model,criterion,batch_size)\n        #  the below line can be uncommenteed for test accuracy and loss\n        #test_accuracy,test_loss = check_accuracy(test_loader, model,criterion,batchSize)\n        print(f\"training_accuracy:{training_accuracy:.4f},training_loss:{training_loss:.4f}\")\n        print(f\"validation_accuracy:{validation_accuracy:.4f},validation_loss:{validation_loss:.4f}\")\n        #print(f\"test_accuracy:{test_accuracy:.4f},test_loss:{test_loss:.4f}\")\n        wandb.log({'training_accuracy':training_accuracy}) # plotting  the data in wandb\n        wandb.log({'training_loss':training_loss})\n        wandb.log({'validation_accuracy':validation_accuracy})\n        wandb.log({'validation_loss':validation_loss})","metadata":{"id":"tjVu69UXSi6X","trusted":true,"execution":{"iopub.status.busy":"2025-04-18T13:06:12.561373Z","iopub.execute_input":"2025-04-18T13:06:12.561607Z","iopub.status.idle":"2025-04-18T13:06:12.569144Z","shell.execute_reply.started":"2025-04-18T13:06:12.561592Z","shell.execute_reply":"2025-04-18T13:06:12.568520Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# Sweep config for wandb plotting\n# wandb.init(project ='DA6401_Assignment_2')\nsweep_config = {\n    'name'  : \"run_part_b\",\n    'method': 'bayes',\n    'metric': {\n      'name': 'validation_accuracy',\n      'goal': 'maximize'\n    },\n    'parameters': {\n        'batch_size': {\n            'values': [32, 64]\n        },\n        'no_of_epochs': {\n            'values': [5,10]\n        },\n        'learning_rate': {\n            'values': [1e-3, 1e-4]\n        },\n        'augmentation_flag': {\n            'values': ['yes','no']\n        },\n        'strategy_flag': {\n            'values': [2]\n        }\n    }\n}\n\n# sweep_id = wandb.sweep(sweep_config, project=\"DA6401_Assignment_2\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aFev94lk6P5v","outputId":"9186cd5b-9628-4708-a8d5-e979d37d1598","trusted":true,"execution":{"iopub.status.busy":"2025-04-18T13:06:17.589020Z","iopub.execute_input":"2025-04-18T13:06:17.589695Z","iopub.status.idle":"2025-04-18T13:06:17.593892Z","shell.execute_reply.started":"2025-04-18T13:06:17.589668Z","shell.execute_reply":"2025-04-18T13:06:17.593110Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def run_experiment():\n    try:\n        run = wandb.init()  # No config argument here\n        cfg = run.config\n        run.name = (\n            f\"Batch_size: {cfg.batch_size}, \"\n            f\"No_of_epochs: {cfg.no_of_epochs}, \"\n            f\"Learning_Rate: {cfg.learning_rate}, \"\n            f\"Augmentation_flag: {cfg.augmentation_flag}, \"\n            f\"Strategy_flag: {cfg.strategy_flag}\"\n        )\n        train_the_model(\n            cfg.batch_size,\n            cfg.no_of_epochs,\n            cfg.learning_rate,\n            cfg.augmentation_flag,\n            cfg.strategy_flag,\n            10\n        )\n    except Exception as e:\n        print(f\"Error during training: {e}\")\n        if wandb.run:\n            wandb.finish(exit_code=1)\n        raise\n    finally:\n        if wandb.run:\n            wandb.finish\nif __name__==\"__main__\":\n    sweep_id = wandb.sweep(sweep_config, project=\"DA6401_Assignment_2\")\n    wandb.agent(sweep_id, run_experiment ,  count=1)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"eWap7rHM6S3v","outputId":"2465c9f6-7d5d-437d-ba0b-655d9c8e13a0","trusted":true,"execution":{"iopub.status.busy":"2025-04-18T13:06:21.547183Z","iopub.execute_input":"2025-04-18T13:06:21.547749Z","iopub.status.idle":"2025-04-18T13:16:00.637188Z","shell.execute_reply.started":"2025-04-18T13:06:21.547726Z","shell.execute_reply":"2025-04-18T13:16:00.636562Z"}},"outputs":[{"name":"stdout","text":"Create sweep with ID: t8hxnsc8\nSweep URL: https://wandb.ai/cs24m047-iitm-ac-in/DA6401_Assignment_2/sweeps/t8hxnsc8\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8myk31o4 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \taugmentation_flag: no\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tno_of_epochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tstrategy_flag: 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250418_130628-8myk31o4</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs24m047-iitm-ac-in/DA6401_Assignment_2/runs/8myk31o4' target=\"_blank\">azure-sweep-1</a></strong> to <a href='https://wandb.ai/cs24m047-iitm-ac-in/DA6401_Assignment_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m047-iitm-ac-in/DA6401_Assignment_2/sweeps/t8hxnsc8' target=\"_blank\">https://wandb.ai/cs24m047-iitm-ac-in/DA6401_Assignment_2/sweeps/t8hxnsc8</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs24m047-iitm-ac-in/DA6401_Assignment_2' target=\"_blank\">https://wandb.ai/cs24m047-iitm-ac-in/DA6401_Assignment_2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs24m047-iitm-ac-in/DA6401_Assignment_2/sweeps/t8hxnsc8' target=\"_blank\">https://wandb.ai/cs24m047-iitm-ac-in/DA6401_Assignment_2/sweeps/t8hxnsc8</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs24m047-iitm-ac-in/DA6401_Assignment_2/runs/8myk31o4' target=\"_blank\">https://wandb.ai/cs24m047-iitm-ac-in/DA6401_Assignment_2/runs/8myk31o4</a>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n100%|██████████| 97.8M/97.8M [00:00<00:00, 204MB/s]\n100%|██████████| 125/125 [01:11<00:00,  1.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"training_accuracy:72.2625,training_loss:0.8466\nvalidation_accuracy:70.2851,validation_loss:0.9271\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 125/125 [00:46<00:00,  2.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"training_accuracy:76.7875,training_loss:0.6943\nvalidation_accuracy:74.0870,validation_loss:0.8264\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 125/125 [00:45<00:00,  2.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"training_accuracy:78.0375,training_loss:0.6665\nvalidation_accuracy:75.3377,validation_loss:0.8039\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 125/125 [00:46<00:00,  2.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"training_accuracy:78.4250,training_loss:0.6405\nvalidation_accuracy:74.5873,validation_loss:0.7988\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 125/125 [00:45<00:00,  2.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"training_accuracy:80.0000,training_loss:0.5997\nvalidation_accuracy:75.0375,validation_loss:0.7836\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>training_accuracy</td><td>▁▅▆▇█</td></tr><tr><td>training_loss</td><td>█▄▃▂▁</td></tr><tr><td>validation_accuracy</td><td>▁▆█▇█</td></tr><tr><td>validation_loss</td><td>█▃▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>training_accuracy</td><td>80</td></tr><tr><td>training_loss</td><td>0.5997</td></tr><tr><td>validation_accuracy</td><td>75.03752</td></tr><tr><td>validation_loss</td><td>0.78355</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">Batch_size: 64, No_of_epochs: 5, Learning_Rate: 0.001, Augmentation_flag: no, Strategy_flag: 2</strong> at: <a href='https://wandb.ai/cs24m047-iitm-ac-in/DA6401_Assignment_2/runs/8myk31o4' target=\"_blank\">https://wandb.ai/cs24m047-iitm-ac-in/DA6401_Assignment_2/runs/8myk31o4</a><br> View project at: <a href='https://wandb.ai/cs24m047-iitm-ac-in/DA6401_Assignment_2' target=\"_blank\">https://wandb.ai/cs24m047-iitm-ac-in/DA6401_Assignment_2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250418_130628-8myk31o4/logs</code>"},"metadata":{}}],"execution_count":14}]}