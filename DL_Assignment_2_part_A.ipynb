{
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 30673,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dhanushsirigineedi/DL_Assignment_2/blob/main/DL_Assignment_2_part_A.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "import math\n",
        "# Required libraries are imported"
      ],
      "metadata": {
        "id": "3jThqkXDJIQ0",
        "execution": {
          "iopub.status.busy": "2024-04-03T19:16:24.211839Z",
          "iopub.execute_input": "2024-04-03T19:16:24.212386Z",
          "iopub.status.idle": "2024-04-03T19:16:35.503639Z",
          "shell.execute_reply.started": "2024-04-03T19:16:24.212358Z",
          "shell.execute_reply": "2024-04-03T19:16:35.502758Z"
        },
        "trusted": true
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "import socket\n",
        "socket.setdefaulttimeout(30)\n",
        "wandb.login()\n",
        "wandb.init(project ='DA6401_Assignment_2')"
      ],
      "metadata": {
        "id": "NCprfCfLdHvK",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/wandb_datasets/nature_12K.zip -O nature_12K.zip\n",
        "!unzip -q nature_12K.zip"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-03T19:16:35.511151Z",
          "iopub.execute_input": "2024-04-03T19:16:35.511413Z",
          "iopub.status.idle": "2024-04-03T19:17:23.826124Z",
          "shell.execute_reply.started": "2024-04-03T19:16:35.511390Z",
          "shell.execute_reply": "2024-04-03T19:17:23.824802Z"
        },
        "trusted": true,
        "id": "o2UqlZXLfBWl",
        "outputId": "a37e690f-f2cf-40ca-964c-c3c94a6fc021"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "--2024-04-03 19:16:36--  https://storage.googleapis.com/wandb_datasets/nature_12K.zip\nResolving storage.googleapis.com (storage.googleapis.com)... 142.251.180.207, 142.251.172.207, 108.177.112.207, ...\nConnecting to storage.googleapis.com (storage.googleapis.com)|142.251.180.207|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3816687935 (3.6G) [application/zip]\nSaving to: 'nature_12K.zip'\n\nnature_12K.zip      100%[===================>]   3.55G   194MB/s    in 19s     \n\n2024-04-03 19:16:55 (193 MB/s) - 'nature_12K.zip' saved [3816687935/3816687935]\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm nature_12K.zip"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-03T19:17:26.377205Z",
          "iopub.execute_input": "2024-04-03T19:17:26.377699Z",
          "iopub.status.idle": "2024-04-03T19:17:27.380029Z",
          "shell.execute_reply.started": "2024-04-03T19:17:26.377649Z",
          "shell.execute_reply": "2024-04-03T19:17:27.378800Z"
        },
        "trusted": true,
        "id": "g6_c5_CYfBWm",
        "outputId": "7869c52d-3ff2-4535-d453-3598815040c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "rm: cannot remove 'nature_12K.zip': No such file or directory\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def intialize_the_model(self, no_of_input_channels=3, no_of_classes=10,no_of_filters_in_base=32,size_of_filter=3,no_of_neurons=128,\n",
        "                            activation_function='sigmoid',dropout_probability=0.0,batch_normalization='no',filter_organizing_mode=0):\n",
        "        super(CNN, self).intialize_the_model()\n",
        "        self.activation_function_name = activation_function\n",
        "        self.batch_normalization = batch_normalization\n",
        "        if(org ==  0): # the filters are same\n",
        "            no_of_filters = [no_of_filters_in_base,no_of_filters_in_base,no_of_filters_in_base,no_of_filters_in_base,no_of_filters_in_base]\n",
        "        else:\n",
        "            no_of_filters = [no_of_filters_in_base,no_of_filters_in_base*2,no_of_filters_in_base*4,no_of_filters_in_base*8,no_of_filters_in_base*16] # the filters increase by *2\n",
        "        width = 0.0\n",
        "        height = 0.0\n",
        "\n",
        "        self.conv_layer1 = nn.Conv2d(in_channels=no_of_input_channels,out_channels=no_of_filters[0],kernel_size=size_of_filter, stride=1)\n",
        "        width = (256 - size_of_filter)+1 #256 --> width of image\n",
        "        height = (256 - size_of_filter)+1 #256 --> height of image\n",
        "        self.batch_norm1 = nn.BatchNorm2d(no_of_filters[0])  # batch normalizations\n",
        "        self.pool_layer1 = nn.MaxPool2d(kernel_size=size_of_filter, stride=2)\n",
        "        width = math.floor((width - size_of_filter)/2) + 1 # width  calculatios of feature map\n",
        "        height = math.floor((height -size_of_filter)/2) + 1 # hight calculations of feature map\n",
        "\n",
        "        self.conv_layer2 = nn.Conv2d( in_channels=no_of_filters[0], out_channels=no_of_filters[1], kernel_size=size_of_filter, stride=1)\n",
        "        width = ((width - size_of_filter))+1\n",
        "        height = ((height-size_of_filter))+1\n",
        "        self.batch_norm2 = nn.BatchNorm2d(no_of_filters[1])  # batch normalizations\n",
        "        self.pool_layer2 = nn.MaxPool2d(kernel_size=size_of_filter, stride=2)\n",
        "        width = math.floor((width - size_of_filter)/2) + 1 # width  calculatios of feature map\n",
        "        height = math.floor((height -size_of_filter)/2) + 1 # hight calculations of feature map\n",
        "\n",
        "        self.conv_layer3 = nn.Conv2d( in_channels=no_of_filters[1], out_channels=no_of_filters[2], kernel_size=size_of_filter, stride=1)\n",
        "        width = ((width - size_of_filter))+1\n",
        "        height = ((height-size_of_filter))+1\n",
        "        self.batch_norm3 = nn.BatchNorm2d(no_of_filters[2])  # batch normalizations\n",
        "        self.pool_layer3 = nn.MaxPool2d(kernel_size=size_of_filter, stride=2)\n",
        "        width = math.floor((width - size_of_filter)/2) + 1 # width  calculatios of feature map\n",
        "        height = math.floor((height -size_of_filter)/2) + 1 # hight calculations of feature map\n",
        "\n",
        "        self.conv_layer4 = nn.Conv2d( in_channels=no_of_filters[2], out_channels=no_of_filters[3], kernel_size=size_of_filter, stride=1)\n",
        "        width = ((width - size_of_filter))+1\n",
        "        height = ((height-size_of_filter))+1\n",
        "        self.batch_norm4 = nn.BatchNorm2d(no_of_filters[3])  # batch normalizations\n",
        "        self.pool_layer4 = nn.MaxPool2d(kernel_size=size_of_filter, stride=2)\n",
        "        width = math.floor((width - size_of_filter)/2) + 1 # width  calculatios of feature map\n",
        "        height = math.floor((height -size_of_filter)/2) + 1 # hight calculations of feature map\n",
        "\n",
        "        self.conv_layer5 = nn.Conv2d( in_channels=no_of_filters[3], out_channels=no_of_filters[4], kernel_size=size_of_filter, stride=1)\n",
        "        width = ((width - size_of_filter))+1\n",
        "        height = ((height-size_of_filter))+1\n",
        "        self.batch_norm5 = nn.BatchNorm2d(no_of_filters[4])  # batch normalizations\n",
        "        self.pool_layer5 = nn.MaxPool2d(kernel_size=size_of_filter, stride=2)\n",
        "        width = math.floor((width - size_of_filter)/2) + 1 # width  calculatios of feature map\n",
        "        height = math.floor((height -size_of_filter)/2) + 1 # hight calculations of feature map\n",
        "\n",
        "        self.dropout = nn.Dropout(p=dropout_probability) # added dropout to overcome overfitting.\n",
        "        self.full_connected1 = nn.Linear(no_of_filters[4] * width*height, no_of_neurons) # dense layer\n",
        "        self.batch_norm6 = nn.BatchNorm1d(no_of_neurons)\n",
        "        self.full_connected2 = nn.Linear(no_of_neurons,10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if(self.activation_function_name == 'relu'):\n",
        "            activation_function = F.relu\n",
        "        elif(self.activation_function_name == 'gelu'):\n",
        "            activation_function = F.gelu\n",
        "        elif(self.activation_function_name == 'silu'):\n",
        "            activation_function = F.silu\n",
        "        else:\n",
        "            activation_function = F.mish\n",
        "\n",
        "        if(self.batch_normalization == 'yes'):\n",
        "            x = activation_function(self.batch_norm1(self.conv_layer1(x)))\n",
        "        else:\n",
        "            x = activation_function(self.conv_layer1(x))\n",
        "        x = self.pool_layer1(x)\n",
        "\n",
        "        if(self.batch_normalization == 'yes'):\n",
        "            x = activation_function(self.batch_norm2(self.conv_layer2(x)))\n",
        "        else:\n",
        "            x = activation_function(self.conv_layer2(x))\n",
        "        x = self.pool_layer2(x)\n",
        "\n",
        "        if(self.batch_normalization == 'yes'):\n",
        "            x = activation_function(self.batch_norm3(self.conv_layer3(x)))\n",
        "        else:\n",
        "            x = activation_function(self.conv_layer3(x))\n",
        "        x = self.pool_layer3(x)\n",
        "\n",
        "        if(self.batch_normalization == 'yes'):\n",
        "            x = activation_function(self.batch_norm4(self.conv_layer4(x)))\n",
        "        else:\n",
        "            x = activation_function(self.conv_layer4(x))\n",
        "        x = self.pool_layer4(x)\n",
        "\n",
        "        if(self.batch_normalization == 'yes'):\n",
        "            x = activation_function(self.batch_norm5(self.conv_layer5(x)))\n",
        "        else:\n",
        "            x = activation_function(self.conv_layer5(x))\n",
        "        x = self.pool_layer5(x)\n",
        "\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        if(self.batch_normalization == 'yes'):\n",
        "            x = activation_function(self.batch_norm6(self.fc1(x)))\n",
        "        else:\n",
        "            x = activation_function(self.full_connected1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.full_connected2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "FsGQWkx6JNw4",
        "execution": {
          "iopub.status.busy": "2024-04-03T19:19:55.704586Z",
          "iopub.execute_input": "2024-04-03T19:19:55.705270Z",
          "iopub.status.idle": "2024-04-03T19:19:55.730853Z",
          "shell.execute_reply.started": "2024-04-03T19:19:55.705233Z",
          "shell.execute_reply": "2024-04-03T19:19:55.729886Z"
        },
        "trusted": true
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "82Wbat2GLjXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform_basic = transforms.Compose([\n",
        "    transforms.Resize((256,256)), # resized to a threshold value so that all images have same shape and size\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,),(0.5,))]) # normalized for better accuracy.\n",
        "\n",
        "train_dataset = datasets.ImageFolder(root=\"inaturalist_12K\\train\",transform=transform_basic) # train_data loading\n",
        "train_dataset,val_dataset = torch.utils.data.random_split(train_dataset,[8000,1999]) #splitting the data into 80%(training) and 20%(validation) The overall data size is 9999\n",
        "\n",
        "transform_augmented = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),  # Randomly flip the image horizontally\n",
        "    transforms.RandomRotation(10),      # Randomly rotate the image by a maximum of 10 degrees\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Adjust brightness, contrast, saturation, and hue\n",
        "    transforms.RandomResizedCrop(256),  # Randomly crop and resize the image to 256x256\n",
        "    transforms.ToTensor(),              # Convert the image to a PyTorch tensor\n",
        "    transforms.Normalize((0.5,),(0.5,))  # Normalize the image\n",
        "]) # for augumenting the training data\n",
        "train_dataset2 = datasets.ImageFolder(root=\"inaturalist_12K\\ train\",transform=transform_augmented)\n",
        "train_dataset_aug,val_dataset_aug = torch.utils.data.random_split(train_dataset2,[8000,1999]) #  #splitting the data into 80%(training) and 20%(validation) The overall data size is 9999\n",
        "\n",
        "test_data = datasets.ImageFolder(root=\"inaturalist_12K\\ val\",transform=transform_basic); # test data loading."
      ],
      "metadata": {
        "id": "s8RAqFPBLkF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_loader_creator(augmentation_flag,batch_size): # function to return the data loaders depending on augumentation.\n",
        "    if(augmentation_flag == 'no'):\n",
        "        train_loader = torch.utils.data.DataLoader(train_dataset,batch_size =batch_size,shuffle = True,num_workers=2,pin_memory=True)\n",
        "        val_loader = torch.utils.data.DataLoader(val_dataset,batch_size =batch_size,shuffle = True,num_workers=2,pin_memory=True)\n",
        "        return train_loader,val_loader\n",
        "    else:\n",
        "        train_loader_aug = torch.utils.data.DataLoader(train_dataset_aug,batch_size =batch_size,shuffle = True,num_workers=4,pin_memory=True)\n",
        "        val_loader_aug = torch.utils.data.DataLoader(val_dataset_aug,batch_size =batch_size,shuffle = True,num_workers=4,pin_memory=True)\n",
        "        return train_loader_aug,val_loader_aug"
      ],
      "metadata": {
        "id": "xwvPIxbbQwJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Accuracy_calculator(loader,model,criterion,batch_size): # function to clculate the accuracy and loss\n",
        "    no_of_correct_predictions = 0\n",
        "    no_of_samples = 0\n",
        "    total_loss = 0.0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(device=device)\n",
        "            y = y.to(device=device)\n",
        "            scores = model(x)\n",
        "            loss = criterion(scores, y)\n",
        "            total_loss += loss.item()*batch_size # sum of cross entropies\n",
        "            _, predictions = scores.max(1)\n",
        "            num_correct += (predictions == y).sum().item() # correctly classified data\n",
        "            num_samples += predictions.size(0)\n",
        "    model.train()\n",
        "    return (num_correct / num_samples)*100 , total_loss"
      ],
      "metadata": {
        "id": "Yq0mYvsqWZp0"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_the_model(no_of_neurons,no_of_filters,size_of_filter,activation_function_name,optimizer_name,batch_size,\n",
        "                    dropout_probability,no_of_epochs,learning_rate,batch_normalization,augmentation_flag,filter_organizing_mode):\n",
        "\n",
        "    train_loader,val_loader = data_loader_creator(augmentation_flag,batch_size)  # getting dataloaders.\n",
        "\n",
        "    #test_loader = torch.utils.data.DataLoader(test_data,batch_size =batchSize,shuffle = True,num_workers=2,pin_memory=True)\n",
        "\n",
        "    no_of_input_channels=3\n",
        "    no_of_classes=10\n",
        "\n",
        "    model=CNN(no_of_input_channels, no_of_classes,no_of_filters,size_of_filter,no_of_neurons,activation_function_name,dropout_probability,batch_normalization,filter_organizing_mode).to(device)\n",
        "\n",
        "    if(optimizer_name == 'sgd'):\n",
        "        optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "    elif(optimizer_name == 'adam'):\n",
        "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    else:\n",
        "      optimizer = optim.NAdam(model.parameters(), lr=learning_rate) # optimzers selection\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss() # since it is classification problem corss entropy loss is used.\n",
        "\n",
        "    for epoch in range(no_of_epochs): # performs the training.\n",
        "        for batchId, (input_images, target_classes) in enumerate(tqdm(train_loader)):\n",
        "            # Get data to cuda if possible\n",
        "            input_images = input_images.to(device=device)\n",
        "            target_classes = target_classes.to(device=device)\n",
        "            # forward\n",
        "            scores = model(input_images) # give the last layer pre-activation values.\n",
        "            loss = criterion(scores,target_classes) # gets the overll cross entropy loss for each batch\n",
        "            optimizer.zero_grad() # gradients are made to zero for each batch.\n",
        "            loss.backward()  # calculaing the gradients\n",
        "            optimizer.step() #updates the parameters\n",
        "        training_accuracy,training_loss = Accuracy_calculator(train_loader, model,criterion,batch_size) # calculates the accuracy and loss at one go\n",
        "        validation_accuracy,validation_loss = Accuracy_calculator(val_loader, model,criterion,batch_size)\n",
        "        #  the below line can be uncommenteed for test accuracy and loss\n",
        "        #test_accuracy,test_loss = check_accuracy(test_loader, model,criterion,batchSize)\n",
        "        print(f\"training_accuracy:{training_accuracy:.4f},training_loss:{training_loss:.4f}\")\n",
        "        print(f\"validation_accuracy:{validation_accuracy:.4f},validation_loss:{validation_loss:.4f}\")\n",
        "        #print(f\"test_accuracy:{test_accuracy:.4f},test_loss:{test_loss:.4f}\")\n",
        "        # wandb.log({'training_accuracy':training_accuracy}) # plotting  the data in wandb\n",
        "        # wandb.log({'training_loss':training_loss})\n",
        "        # wandb.log({'validation_accuracy':validation_accuracy})\n",
        "        # wandb.log({'validation_loss':validation_loss})"
      ],
      "metadata": {
        "id": "tjVu69UXSi6X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}