{
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 30673,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dhanushsirigineedi/DL_Assignment_2/blob/main/DL_Assignment_2_part_A.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "import math\n",
        "# Required libraries are imported"
      ],
      "metadata": {
        "id": "3jThqkXDJIQ0",
        "execution": {
          "iopub.status.busy": "2024-04-03T19:16:24.211839Z",
          "iopub.execute_input": "2024-04-03T19:16:24.212386Z",
          "iopub.status.idle": "2024-04-03T19:16:35.503639Z",
          "shell.execute_reply.started": "2024-04-03T19:16:24.212358Z",
          "shell.execute_reply": "2024-04-03T19:16:35.502758Z"
        },
        "trusted": true
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "import socket\n",
        "socket.setdefaulttimeout(30)\n",
        "wandb.login()\n",
        "wandb.init(project ='DA6401_Assignment_2')"
      ],
      "metadata": {
        "id": "NCprfCfLdHvK",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/wandb_datasets/nature_12K.zip -O nature_12K.zip\n",
        "!unzip -q nature_12K.zip"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-03T19:16:35.511151Z",
          "iopub.execute_input": "2024-04-03T19:16:35.511413Z",
          "iopub.status.idle": "2024-04-03T19:17:23.826124Z",
          "shell.execute_reply.started": "2024-04-03T19:16:35.511390Z",
          "shell.execute_reply": "2024-04-03T19:17:23.824802Z"
        },
        "trusted": true,
        "id": "o2UqlZXLfBWl",
        "outputId": "a37e690f-f2cf-40ca-964c-c3c94a6fc021"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "--2024-04-03 19:16:36--  https://storage.googleapis.com/wandb_datasets/nature_12K.zip\nResolving storage.googleapis.com (storage.googleapis.com)... 142.251.180.207, 142.251.172.207, 108.177.112.207, ...\nConnecting to storage.googleapis.com (storage.googleapis.com)|142.251.180.207|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3816687935 (3.6G) [application/zip]\nSaving to: 'nature_12K.zip'\n\nnature_12K.zip      100%[===================>]   3.55G   194MB/s    in 19s     \n\n2024-04-03 19:16:55 (193 MB/s) - 'nature_12K.zip' saved [3816687935/3816687935]\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm nature_12K.zip"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-03T19:17:26.377205Z",
          "iopub.execute_input": "2024-04-03T19:17:26.377699Z",
          "iopub.status.idle": "2024-04-03T19:17:27.380029Z",
          "shell.execute_reply.started": "2024-04-03T19:17:26.377649Z",
          "shell.execute_reply": "2024-04-03T19:17:27.378800Z"
        },
        "trusted": true,
        "id": "g6_c5_CYfBWm",
        "outputId": "7869c52d-3ff2-4535-d453-3598815040c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "rm: cannot remove 'nature_12K.zip': No such file or directory\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def intialize_the_model(self, no_of_input_channels=3, no_of_classes=10,no_of_filters_in_base=32,size_of_filter=3,no_of_neurons=128,\n",
        "                            activation_function='sigmoid',dropout_probability=0.0,batch_normalization='no',filter_organizing_mode=0):\n",
        "        super(CNN, self).intialize_the_model()\n",
        "        self.activation_function_name = activation_function\n",
        "        self.batch_normalization = batch_normalization\n",
        "        if(org ==  0): # the filters are same\n",
        "            no_of_filters = [no_of_filters_in_base,no_of_filters_in_base,no_of_filters_in_base,no_of_filters_in_base,no_of_filters_in_base]\n",
        "        else:\n",
        "            no_of_filters = [no_of_filters_in_base,no_of_filters_in_base*2,no_of_filters_in_base*4,no_of_filters_in_base*8,no_of_filters_in_base*16] # the filters increase by *2\n",
        "        width = 0.0\n",
        "        height = 0.0\n",
        "\n",
        "        self.conv_layer1 = nn.Conv2d(in_channels=no_of_input_channels,out_channels=no_of_filters[0],kernel_size=size_of_filter, stride=1)\n",
        "        width = (256 - size_of_filter)+1 #256 --> width of image\n",
        "        height = (256 - size_of_filter)+1 #256 --> height of image\n",
        "        self.batch_norm1 = nn.BatchNorm2d(no_of_filters[0])  # batch normalizations\n",
        "        self.pool_layer1 = nn.MaxPool2d(kernel_size=size_of_filter, stride=2)\n",
        "        width = math.floor((width - size_of_filter)/2) + 1 # width  calculatios of feature map\n",
        "        height = math.floor((height -size_of_filter)/2) + 1 # hight calculations of feature map\n",
        "\n",
        "        self.conv_layer2 = nn.Conv2d( in_channels=no_of_filters[0], out_channels=no_of_filters[1], kernel_size=size_of_filter, stride=1)\n",
        "        width = ((width - size_of_filter))+1\n",
        "        height = ((height-size_of_filter))+1\n",
        "        self.batch_norm2 = nn.BatchNorm2d(no_of_filters[1])  # batch normalizations\n",
        "        self.pool_layer2 = nn.MaxPool2d(kernel_size=size_of_filter, stride=2)\n",
        "        width = math.floor((width - size_of_filter)/2) + 1 # width  calculatios of feature map\n",
        "        height = math.floor((height -size_of_filter)/2) + 1 # hight calculations of feature map\n",
        "\n",
        "        self.conv_layer3 = nn.Conv2d( in_channels=no_of_filters[1], out_channels=no_of_filters[2], kernel_size=size_of_filter, stride=1)\n",
        "        width = ((width - size_of_filter))+1\n",
        "        height = ((height-size_of_filter))+1\n",
        "        self.batch_norm3 = nn.BatchNorm2d(no_of_filters[2])  # batch normalizations\n",
        "        self.pool_layer3 = nn.MaxPool2d(kernel_size=size_of_filter, stride=2)\n",
        "        width = math.floor((width - size_of_filter)/2) + 1 # width  calculatios of feature map\n",
        "        height = math.floor((height -size_of_filter)/2) + 1 # hight calculations of feature map\n",
        "\n",
        "        self.conv_layer4 = nn.Conv2d( in_channels=no_of_filters[2], out_channels=no_of_filters[3], kernel_size=size_of_filter, stride=1)\n",
        "        width = ((width - size_of_filter))+1\n",
        "        height = ((height-size_of_filter))+1\n",
        "        self.batch_norm4 = nn.BatchNorm2d(no_of_filters[3])  # batch normalizations\n",
        "        self.pool_layer4 = nn.MaxPool2d(kernel_size=size_of_filter, stride=2)\n",
        "        width = math.floor((width - size_of_filter)/2) + 1 # width  calculatios of feature map\n",
        "        height = math.floor((height -size_of_filter)/2) + 1 # hight calculations of feature map\n",
        "\n",
        "        self.conv_layer5 = nn.Conv2d( in_channels=no_of_filters[3], out_channels=no_of_filters[4], kernel_size=size_of_filter, stride=1)\n",
        "        width = ((width - size_of_filter))+1\n",
        "        height = ((height-size_of_filter))+1\n",
        "        self.batch_norm5 = nn.BatchNorm2d(no_of_filters[4])  # batch normalizations\n",
        "        self.pool_layer5 = nn.MaxPool2d(kernel_size=size_of_filter, stride=2)\n",
        "        width = math.floor((width - size_of_filter)/2) + 1 # width  calculatios of feature map\n",
        "        height = math.floor((height -size_of_filter)/2) + 1 # hight calculations of feature map\n",
        "\n",
        "        self.dropout = nn.Dropout(p=dropout_probability) # added dropout to overcome overfitting.\n",
        "        self.full_connected1 = nn.Linear(no_of_filters[4] * width*height, no_of_neurons) # dense layer\n",
        "        self.batch_norm6 = nn.BatchNorm1d(no_of_neurons)\n",
        "        self.full_connected2 = nn.Linear(no_of_neurons,10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if(self.activation_function_name == 'relu'):\n",
        "            activation_function = F.relu\n",
        "        elif(self.activation_function_name == 'gelu'):\n",
        "            activation_function = F.gelu\n",
        "        elif(self.activation_function_name == 'silu'):\n",
        "            activation_function = F.silu\n",
        "        else:\n",
        "            activation_function = F.mish\n",
        "\n",
        "        if(self.batch_normalization == 'yes'):\n",
        "            x = activation_function(self.batch_norm1(self.conv_layer1(x)))\n",
        "        else:\n",
        "            x = activation_function(self.conv_layer1(x))\n",
        "        x = self.pool_layer1(x)\n",
        "\n",
        "        if(self.batch_normalization == 'yes'):\n",
        "            x = activation_function(self.batch_norm2(self.conv_layer2(x)))\n",
        "        else:\n",
        "            x = activation_function(self.conv_layer2(x))\n",
        "        x = self.pool_layer2(x)\n",
        "\n",
        "        if(self.batch_normalization == 'yes'):\n",
        "            x = activation_function(self.batch_norm3(self.conv_layer3(x)))\n",
        "        else:\n",
        "            x = activation_function(self.conv_layer3(x))\n",
        "        x = self.pool_layer3(x)\n",
        "\n",
        "        if(self.batch_normalization == 'yes'):\n",
        "            x = activation_function(self.batch_norm4(self.conv_layer4(x)))\n",
        "        else:\n",
        "            x = activation_function(self.conv_layer4(x))\n",
        "        x = self.pool_layer4(x)\n",
        "\n",
        "        if(self.batch_normalization == 'yes'):\n",
        "            x = activation_function(self.batch_norm5(self.conv_layer5(x)))\n",
        "        else:\n",
        "            x = activation_function(self.conv_layer5(x))\n",
        "        x = self.pool_layer5(x)\n",
        "\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        if(self.batch_normalization == 'yes'):\n",
        "            x = activation_function(self.batch_norm6(self.fc1(x)))\n",
        "        else:\n",
        "            x = activation_function(self.full_connected1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.full_connected2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "FsGQWkx6JNw4",
        "execution": {
          "iopub.status.busy": "2024-04-03T19:19:55.704586Z",
          "iopub.execute_input": "2024-04-03T19:19:55.705270Z",
          "iopub.status.idle": "2024-04-03T19:19:55.730853Z",
          "shell.execute_reply.started": "2024-04-03T19:19:55.705233Z",
          "shell.execute_reply": "2024-04-03T19:19:55.729886Z"
        },
        "trusted": true
      },
      "execution_count": 4,
      "outputs": []
    }
  ]
}